# Corrective RAG (CRAG) with LangGraph

This project implements a simplified version of the Corrective-RAG (CRAG) framework using **LangGraph**, a self-reflective Retrieval-Augmented Generation (RAG) strategy that incorporates dynamic feedback and correction mechanisms during the retrieval process.

---

## ğŸ§  What is CRAG?

CRAG enhances the standard RAG pipeline by:

- **Grading retrieved documents for relevance** before generation.  
- **Supplementing retrieval with web search** if documents are irrelevant or uncertain.  
- (Optionally) **refining knowledge through partitioning into "knowledge strips"** â€” skipped in this version for simplicity.

---

## âœ… Key Features in This Implementation

- **Relevance Grading:** Retrieved documents are graded for relevance.  
- **Conditional Generation:** Generation only proceeds if relevant context is available.  
- **Fallback to Web Search:** If retrieved content is irrelevant or insufficient, the query is rewritten and a web search is performed using Tavily Search.  
- **Query Rewriting:** Enhances the original user query for better supplemental search results.  
- **FastAPI Integration:** Provides an API for programmatic access to CRAG.
  - `/query` endpoint for normal query-response interaction  
  - `/stream` endpoint for real-time streaming of generated answers  
- **Frontend UI:** Minimal web interface for submitting questions and viewing answers/documents.

> **Note:** Knowledge refinement (splitting into "knowledge strips" and further grading) is omitted in this version but can be added as a separate node in LangGraph later.

---

## ğŸ› ï¸ Tech Stack

- **LangGraph** â€“ for building a dynamic, self-reflective RAG workflow  
- **LangSmith** â€“ for tracing, debugging, and monitoring the RAG pipeline  
- **DuckDuckGo Search (via tool)** â€“ for real-time supplemental web data  
- **LLama 3.2 3B (via Ollama)** â€“ local language model for grading, query rewriting, and generation  
- **Hugging Face Embeddings** â€“ for dense retrieval of relevant documents  
- **FAISS** â€“ vector store for efficient similarity search over embeddings  
- **FastAPI** â€“ for building the API and streaming endpoint  
- **HTML/JS Frontend** â€“ simple user interface for queries and streaming answers  

---

## âš¡ FastAPI Features

- **POST `/query`** â€“ send a question, receive documents and generated answer.  
- **GET `/stream`** â€“ receive the generated answer in real-time chunks for improved UX.  
- **GET `/`** â€“ minimal web UI to submit questions and display streaming answers alongside retrieved documents.  

**Streaming Example:**

```javascript
const evtSource = new EventSource(`/stream?question=Your question here`);
evtSource.onmessage = function(event) {
    if(event.data !== "[DONE]") {
        console.log(event.data); // partial answer
    }
};
